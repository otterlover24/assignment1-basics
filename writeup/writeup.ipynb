{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "863cef1d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e75378",
   "metadata": {},
   "source": [
    "## Problem (unicode1): Understanding Unicode (1 point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384c259",
   "metadata": {},
   "source": [
    "### (a) \n",
    "#### Question\n",
    "What Unicode character does chr(0) return?\n",
    "\n",
    "Deliverable: A one-sentence response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a1f4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55363103",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "`chr(0)` returns the Unicode character with code point 0, which is the null character (`'\\x00'`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad00e1",
   "metadata": {},
   "source": [
    "### (b) \n",
    "#### Question\n",
    "How does this character’s string representation (__repr__()) differ from its printed representa-\n",
    "tion?\n",
    "\n",
    "Deliverable: A one-sentence response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e8bf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'\\\\x00'\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cdf0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896726ff",
   "metadata": {},
   "source": [
    "The string representation `repr(chr(0))` is `\"'\\\\x00'\"`, showing the escape sequence, while printing `chr(0)` outputs nothing visible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59971619",
   "metadata": {},
   "source": [
    "### (c) \n",
    "#### Question\n",
    "What happens when this character occurs in text? It may be helpful to play around with the\n",
    "following in your Python interpreter and see if it matches your expectations:\n",
    "```\n",
    ">>> chr(0)\n",
    ">>> print(chr(0))\n",
    ">>> \"this is a test\" + chr(0) + \"string\"\n",
    ">>> print(\"this is a test\" + chr(0) + \"string\")\n",
    "```\n",
    "\n",
    "Deliverable: A one-sentence response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6100dceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test\\x00string'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a test\" + chr(0) + \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cebb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\u0000string\n"
     ]
    }
   ],
   "source": [
    "print(\"this is a test\" + chr(0) + \"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0790a",
   "metadata": {},
   "source": [
    "#### Response\n",
    "\n",
    "When the null character occurs in text, it acts as an invisible character and does not display when printed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce47c55c",
   "metadata": {},
   "source": [
    "# Problem (unicode2): Unicode Encodings (3 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d323aea",
   "metadata": {},
   "source": [
    "## (a) \n",
    "### Question\n",
    "What are some reasons to prefer training our tokenizer on UTF-8 encoded bytes, rather than\n",
    "UTF-16 or UTF-32? It may be helpful to compare the output of these encodings for various\n",
    "input strings.\n",
    "\n",
    "Deliverable: A one-to-two sentence response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5cc6f",
   "metadata": {},
   "source": [
    "Training a tokenizer on UTF-8 encoded bytes is preferred because it's a variable-length encoding that efficiently represents common characters with fewer bytes, resulting in a more compact vocabulary and faster processing. Unlike the fixed-width or wider variable-width formats of UTF-32 and UTF-16, UTF-8's design avoids unnecessary padding for frequent characters and handles the full Unicode range without introducing null bytes that can complicate text processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6155e41",
   "metadata": {},
   "source": [
    "## (b) \n",
    "### Question\n",
    "Consider the following (incorrect) function, which is intended to decode a UTF-8 byte string into\n",
    "a Unicode string. Why is this function incorrect? Provide an example of an input byte string\n",
    "that yields incorrect results.\n",
    "```\n",
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    ">>> decode_utf8_bytes_to_str_wrong(\"hello\".encode(\"utf-8\"))\n",
    "'hello'\n",
    "```\n",
    "Deliverable: An example input byte string for which decode_utf8_bytes_to_str_wrong pro-\n",
    "duces incorrect output, with a one-sentence explanation of why the function is incorrect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a543b05a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28mbytes\u001b[39m([b]).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mdecode_utf8_bytes_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mé\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecode_utf8_bytes_to_str_wrong\u001b[39m\u001b[34m(bytestring)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xc3 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    "\n",
    "decode_utf8_bytes_to_str_wrong(\"é\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732405b",
   "metadata": {},
   "source": [
    "An example of an input byte string that fails is 'é'.encode('utf-8'), which evaluates to b'\\xc3\\xa9'.\n",
    "\n",
    "This function is incorrect because it attempts to decode each byte in isolation, whereas many Unicode characters, such as 'é', are represented by multi-byte sequences in UTF-8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51222e3",
   "metadata": {},
   "source": [
    "## (c) \n",
    "### Question\n",
    "Give a two byte sequence that does not decode to any Unicode character(s).\n",
    "\n",
    "Deliverable: An example, with a one-sentence explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4801a0c7",
   "metadata": {},
   "source": [
    "The byte sequence b'\\xc2\\xc2' does not decode to any Unicode character.\n",
    "\n",
    "This sequence is invalid because the first byte (\\xc2) indicates the start of a two-byte character, but the second byte is another start byte rather than the required continuation byte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37522daa",
   "metadata": {},
   "source": [
    "# Problem (train_bpe): BPE Tokenizer Training (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff85ea7",
   "metadata": {},
   "source": [
    "- Deliverable: Write a function that, given a path to an input text file, trains a (byte-level) BPE\n",
    "tokenizer. Your BPE training function should handle (at least) the following input parameters:\n",
    "- input_path: str Path to a text file with BPE tokenizer training data.\n",
    "- vocab_size: int A positive integer that defines the maximum final vocabulary size (including the\n",
    "initial byte vocabulary, vocabulary items produced from merging, and any special tokens).\n",
    "- special_tokens: list[str] A list of strings to add to the vocabulary. These special tokens do not\n",
    "otherwise affect BPE training.\n",
    "\n",
    "Your BPE training function should return the resulting vocabulary and merges:\n",
    "\n",
    "- vocab: dict[int, bytes] The tokenizer vocabulary, a mapping from int (token ID in the vocabu-\n",
    "lary) to bytes (token bytes).\n",
    "- merges: list[tuple[bytes, bytes]] A list of BPE merges produced from training. Each list item\n",
    "is a tuple of bytes (<token1>, <token2>), representing that <token1> was merged with\n",
    "<token2>. The merges should be ordered by order of creation.\n",
    "\n",
    "To test your BPE training function against our provided tests, you will first need to implement the\n",
    "test adapter at [adapters.run_train_bpe]. Then, run uv run pytest tests/test_train_bpe.py.\n",
    "Your implementation should be able to pass all tests. Optionally (this could be a large time-investment),\n",
    "you can implement the key parts of your training method using some systems language, for instance\n",
    "C++ (consider cppyy for this) or Rust (using PyO3). If you do this, be aware of which operations\n",
    "require copying vs reading directly from Python memory, and make sure to leave build instructions, or\n",
    "make sure it builds using only pyproject.toml. Also note that the GPT-2 regex is not well-supported\n",
    "in most regex engines and will be too slow in most that do. We have verified that Oniguruma is\n",
    "reasonably fast and supports negative lookahead, but the regex package in Python is, if anything,\n",
    "even faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d30f7",
   "metadata": {},
   "source": [
    "## (a)\n",
    "\n",
    "Train a byte-level BPE tokenizer on the TinyStories dataset, using a maximum vocabulary size\n",
    "of 10,000. Make sure to add the TinyStories <|endoftext|> special token to the vocabulary.\n",
    "Serialize the resulting vocabulary and merges to disk for further inspection. \n",
    "\n",
    "- How many hours and memory did training take? \n",
    "- What is the longest token in the vocabulary? Does it make sense?\n",
    "\n",
    "Resource requirements: ≤ 30 minutes (no GPUs), ≤ 30GB RAM\n",
    "Hint You should be able to get under 2 minutes for BPE training using multiprocessing during\n",
    "pretokenization and the following two facts:\n",
    "(a) The <|endoftext|> token delimits documents in the data files.\n",
    "(b) The <|endoftext|> token is handled as a special case before the BPE merges are applied.\n",
    "Deliverable: A one-to-two sentence response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660dcc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# # Add the parent directory to Python path\n",
    "# sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "# display(sys.path)\n",
    "\n",
    "# from tests import adapters\n",
    "# import time\n",
    "# from memory_profiler import profile\n",
    "\n",
    "# @profile\n",
    "# def run_train_bpe(input_path: str, vocab_size: int, special_tokens: list):\n",
    "#     vocab, merges = adapters.run_train_bpe(\n",
    "#         input_path=input_path,\n",
    "#         vocab_size=vocab_size,\n",
    "#         special_tokens=[\"<|endoftext|>\"],\n",
    "#     )\n",
    "#     return vocab, merges\n",
    "\n",
    "# start_time = time.time()\n",
    "# vocab, merges = run_train_bpe(\n",
    "#     \"../data/TinyStoriesV2-GPT4-valid.txt\", \n",
    "#     vocab_size=10_000, \n",
    "#     special_tokens=[\"<|endoftext|>\"])\n",
    "# end_time = time.time()\n",
    "\n",
    "# print(f\"Training BPE took {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b39415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mprof: Sampling memory every 0.1s\n",
      "running new process\n",
      "running as a Python program...\n",
      "sys.path = ['/home/tl/projects/learning/natural-language-processing/stanford-cs336/assignment1-basics', '', '/home/tl/projects/learning/natural-language-processing/stanford-cs336/assignment1-basics/writeup', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/home/tl/projects/learning/natural-language-processing/stanford-cs336/assignment1-basics/.venv/lib/python3.12/site-packages']\n",
      "Starting parallel pre-tokenization and counting...\n",
      "Finished pre-tokenization. Found 13111 unique pre-tokens.\n",
      "Starting 9743 BPE merge operations...\n",
      "BPE Merges: 100%|███████████████████████████| 9743/9743 [16:08<00:00, 10.06it/s]\n",
      "BPE training complete.\n",
      "Filename: profile_train_bpe.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    11    397.2 MiB    397.2 MiB           1   @profile\n",
      "    12                                         def run_train_bpe(input_path: str, vocab_size: int, special_tokens: list):\n",
      "    13    414.5 MiB     17.3 MiB           2       vocab, merges = adapters.run_train_bpe(\n",
      "    14    397.2 MiB      0.0 MiB           1           input_path=input_path,\n",
      "    15    397.2 MiB      0.0 MiB           1           vocab_size=vocab_size,\n",
      "    16    397.2 MiB      0.0 MiB           1           special_tokens=[\"<|endoftext|>\"],\n",
      "    17                                             )\n",
      "    18    414.5 MiB      0.0 MiB           1       return vocab, merges\n",
      "\n",
      "\n",
      "Training BPE took 976.69 seconds\n"
     ]
    }
   ],
   "source": [
    "!mprof run profile_train_bpe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "279c7154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using last profile data.\n",
      "Figure(1260x540)\n"
     ]
    }
   ],
   "source": [
    "!mprof plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc038d8d",
   "metadata": {},
   "source": [
    "## (b)\n",
    "\n",
    "Profile your code. What part of the tokenizer training process takes the most time?\n",
    "Deliverable: A one-to-two sentence response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765a54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment1-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
